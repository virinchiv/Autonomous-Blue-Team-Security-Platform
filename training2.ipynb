{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9866a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import json, time, os, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, average_precision_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad62266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  @timestamp     log.source  \\\n",
      "0  2019-01-22T03:56:14+03:30  apache_access   \n",
      "1  2019-01-22T03:56:16+03:30  apache_access   \n",
      "2  2019-01-22T03:56:16+03:30  apache_access   \n",
      "3  2019-01-22T03:56:17+03:30  apache_access   \n",
      "4  2019-01-22T03:56:17+03:30  apache_access   \n",
      "\n",
      "                                             message      source.ip  \\\n",
      "0  54.36.149.41 - - [22/Jan/2019:03:56:14 +0330] ...   54.36.149.41   \n",
      "1  31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"...    31.56.96.51   \n",
      "2  31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"...    31.56.96.51   \n",
      "3  40.77.167.129 - - [22/Jan/2019:03:56:17 +0330]...  40.77.167.129   \n",
      "4  91.99.72.15 - - [22/Jan/2019:03:56:17 +0330] \"...    91.99.72.15   \n",
      "\n",
      "  http.request.method                                       url.original  \\\n",
      "0                 GET  /filter/27|13%20%D9%85%DA%AF%D8%A7%D9%BE%DB%8C...   \n",
      "1                 GET                  /image/60844/productModel/200x200   \n",
      "2                 GET                  /image/61474/productModel/200x200   \n",
      "3                 GET                  /image/14925/productModel/100x100   \n",
      "4                 GET  /product/31893/62100/%D8%B3%D8%B4%D9%88%D8%A7%...   \n",
      "\n",
      "  url.query http.version  http.response.status_code  http.response.body.bytes  \\\n",
      "0               HTTP/1.1                        200                     30577   \n",
      "1               HTTP/1.1                        200                      5667   \n",
      "2               HTTP/1.1                        200                      5379   \n",
      "3               HTTP/1.1                        200                      1696   \n",
      "4               HTTP/1.1                        200                     41483   \n",
      "\n",
      "                 http.request.referrer  \\\n",
      "0                                    -   \n",
      "1  https://www.zanbil.ir/m/filter/b113   \n",
      "2  https://www.zanbil.ir/m/filter/b113   \n",
      "3                                    -   \n",
      "4                                    -   \n",
      "\n",
      "                                 user_agent.original event.category  \\\n",
      "0  Mozilla/5.0 (compatible; AhrefsBot/6.1; +http:...       security   \n",
      "1  Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build...            web   \n",
      "2  Mozilla/5.0 (Linux; Android 6.0; ALE-L21 Build...            web   \n",
      "3  Mozilla/5.0 (compatible; bingbot/2.0; +http://...       security   \n",
      "4  Mozilla/5.0 (Windows NT 6.2; Win64; x64; rv:16...            web   \n",
      "\n",
      "  event.type event.outcome security.flags  \\\n",
      "0     threat       success  [bot_traffic]   \n",
      "1     access       success            NaN   \n",
      "2     access       success            NaN   \n",
      "3     threat       success  [bot_traffic]   \n",
      "4     access       success            NaN   \n",
      "\n",
      "                                                 raw  \n",
      "0  54.36.149.41 - - [22/Jan/2019:03:56:14 +0330] ...  \n",
      "1  31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"...  \n",
      "2  31.56.96.51 - - [22/Jan/2019:03:56:16 +0330] \"...  \n",
      "3  40.77.167.129 - - [22/Jan/2019:03:56:17 +0330]...  \n",
      "4  91.99.72.15 - - [22/Jan/2019:03:56:17 +0330] \"...  \n"
     ]
    }
   ],
   "source": [
    "logs = []\n",
    "with open(\"normalized_logs/output_access-10k.log_ecs.json\") as f:\n",
    "    for line in f:\n",
    "        logs.append(json.loads(line))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(logs)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b52ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events: 10000\n",
      "                 @timestamp      source.ip event.type\n",
      "0 2019-01-22 03:56:14+03:30   54.36.149.41     threat\n",
      "1 2019-01-22 03:56:16+03:30    31.56.96.51     access\n",
      "2 2019-01-22 03:56:16+03:30    31.56.96.51     access\n",
      "3 2019-01-22 03:56:17+03:30  40.77.167.129     threat\n",
      "4 2019-01-22 03:56:17+03:30    91.99.72.15     access\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(logs)\n",
    "# Ensure essential fields exist\n",
    "required = ['@timestamp', 'message', 'source.ip', 'event.type']\n",
    "for r in required:\n",
    "    if r not in df.columns:\n",
    "        df[r] = None\n",
    "\n",
    "# Convert timestamp to pandas datetime\n",
    "df['@timestamp'] = pd.to_datetime(df['@timestamp'], errors='coerce')\n",
    "# label: 1 for threat, 0 for benign (adjust to your labeling field)\n",
    "df['label'] = df['event.type'].astype(str).str.contains('threat', case=False, na=False).astype(int)\n",
    "\n",
    "\n",
    "print('Total events:', len(df))\n",
    "print(df[['@timestamp','source.ip','event.type']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab5dab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing embeddings for 10000 messages...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e3c620d23e4e50ac49bf1f2432aff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14adb375e12b47ec90f033ef62587722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built sequences: (8273, 8, 384) labels distribution: [4523 3750]\n"
     ]
    }
   ],
   "source": [
    "EMBED_MODEL = 'all-MiniLM-L6-v2'\n",
    "embedder = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "# Parameters\n",
    "WINDOW_SIZE = 8 # number of events per sequence (tuned)\n",
    "STRIDE = 1 # sliding stride\n",
    "\n",
    "# Sort by time for grouping\n",
    "df = df.sort_values('@timestamp').reset_index(drop=True)\n",
    "\n",
    "# Optional: filter out events missing message text\n",
    "df = df[df['message'].notnull()].reset_index(drop=True)\n",
    "\n",
    "# Compute embeddings for all messages (batch)\n",
    "batch_texts = df['message'].astype(str).tolist()\n",
    "print('Computing embeddings for', len(batch_texts), 'messages...')\n",
    "embeddings = embedder.encode(batch_texts, show_progress_bar=True)\n",
    "embeddings = np.asarray(embeddings) # shape: (N, D)\n",
    "\n",
    "# Attach embeddings to dataframe index for easy slicing\n",
    "# Build sequences per source.ip\n",
    "sequences = [] # list of arrays shape (W, D)\n",
    "seq_labels = []\n",
    "seq_meta = [] # metadata like last timestamp, source.ip\n",
    "\n",
    "\n",
    "for src, g in tqdm(df.groupby('source.ip')):\n",
    "    idxs = g.index.values\n",
    "    if len(idxs) < 1:\n",
    "        continue\n",
    "    # sliding windows within this group\n",
    "    for start in range(0, len(idxs) - WINDOW_SIZE + 1, STRIDE):\n",
    "        window_idxs = idxs[start:start+WINDOW_SIZE]\n",
    "        seq = embeddings[window_idxs] # (WINDOW_SIZE, D)\n",
    "        label = int(df.loc[window_idxs, 'label'].max())\n",
    "        sequences.append(seq)\n",
    "        seq_labels.append(label)\n",
    "        seq_meta.append({'source.ip': src, 'end_time': df.loc[window_idxs[-1], '@timestamp']})\n",
    "\n",
    "\n",
    "sequences = np.stack(sequences) if len(sequences) > 0 else np.empty((0, WINDOW_SIZE, embeddings.shape[1]))\n",
    "seq_labels = np.array(seq_labels)\n",
    "print('Built sequences:', sequences.shape, 'labels distribution:', np.bincount(seq_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d621a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time split at: 2019-01-22T00:59:58.600000000\n",
      "Train/Val sizes: (6618, 8, 384) (1655, 8, 384)\n"
     ]
    }
   ],
   "source": [
    "# Assemble end times array\n",
    "end_times = np.array([m['end_time'].to_datetime64() if hasattr(m['end_time'], 'to_datetime64') else np.datetime64(m['end_time']) for m in seq_meta])\n",
    "# Compute 80th percentile time as split\n",
    "split_time = np.quantile(end_times.astype('datetime64[ns]').astype(np.int64), 0.8)\n",
    "split_time = np.datetime64(int(split_time), 'ns')\n",
    "print('Time split at:', split_time)\n",
    "\n",
    "\n",
    "train_idx = [i for i,t in enumerate(end_times) if t < split_time]\n",
    "val_idx = [i for i,t in enumerate(end_times) if t >= split_time]\n",
    "\n",
    "\n",
    "X_train = sequences[train_idx]; y_train = seq_labels[train_idx]\n",
    "X_val = sequences[val_idx]; y_val = seq_labels[val_idx]\n",
    "print('Train/Val sizes:', X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f638773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PyTorch datasets\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = SeqDataset(X_train, y_train)\n",
    "val_ds = SeqDataset(X_val, y_val)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ccc4dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized\n"
     ]
    }
   ],
   "source": [
    "EMBED_DIM = sequences.shape[2]\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim=128, num_layers=2, num_classes=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=embed_dim, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, D)\n",
    "        out, _ = self.lstm(x)\n",
    "        last = out[:, -1, :]\n",
    "        return self.fc(last)\n",
    "\n",
    "\n",
    "class TransformerSeqClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, nhead=8, dim_feedforward=256, num_layers=2, num_classes=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1) # will apply to (B, D, W)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        # x: (B, W, D)\n",
    "        # Transformer expects (B, W, D) with d_model=embed_dim\n",
    "        out = self.transformer(x) # (B, W, D)\n",
    "        # pool across time\n",
    "        out = out.transpose(1,2) # (B, D, W)\n",
    "        pooled = self.pool(out).squeeze(-1) # (B, D)\n",
    "        return self.fc(pooled)\n",
    "\n",
    "\n",
    "# Instantiate models\n",
    "lstm_model = LSTMClassifier(EMBED_DIM).to(device)\n",
    "trans_model = TransformerSeqClassifier(EMBED_DIM, nhead=4, num_layers=2).to(device)\n",
    "print('Models initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55641325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    ys, preds, probs = [], [], []\n",
    "    total_loss = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        p = torch.softmax(logits, dim=1)[:,1].cpu().numpy()\n",
    "        pr = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        ys.extend(yb.cpu().numpy())\n",
    "        preds.extend(pr.tolist())\n",
    "        probs.extend(p.tolist())\n",
    "    report = classification_report(ys, preds, output_dict=False)\n",
    "    ap = average_precision_score(ys, probs) if len(set(ys))>1 else None\n",
    "    return total_loss / len(loader.dataset), ys, preds, probs, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca7170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Epoch 1/6 -- train_loss: 0.1889, val_loss: 0.0791, AP: 0.9901641049124024\n",
      "LSTM Epoch 2/6 -- train_loss: 0.0386, val_loss: 0.0852, AP: 0.9947155649888745\n",
      "LSTM Epoch 3/6 -- train_loss: 0.0222, val_loss: 0.0572, AP: 0.9981585252324939\n",
      "LSTM Epoch 4/6 -- train_loss: 0.0216, val_loss: 0.0836, AP: 0.9948843546865536\n",
      "LSTM Epoch 5/6 -- train_loss: 0.0183, val_loss: 0.0656, AP: 0.9974589547959254\n",
      "LSTM Epoch 6/6 -- train_loss: 0.0145, val_loss: 0.0586, AP: 0.9986797837736504\n",
      "LSTM eval:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       981\n",
      "           1       0.98      0.99      0.98       674\n",
      "\n",
      "    accuracy                           0.99      1655\n",
      "   macro avg       0.99      0.99      0.99      1655\n",
      "weighted avg       0.99      0.99      0.99      1655\n",
      "\n",
      "TRANS Epoch 1/6 -- train_loss: 0.0999, val_loss: 0.0041, AP: 1.0\n",
      "TRANS Epoch 2/6 -- train_loss: 0.0039, val_loss: 0.0002, AP: 1.0\n",
      "TRANS Epoch 3/6 -- train_loss: 0.0051, val_loss: 0.0001, AP: 1.0\n",
      "TRANS Epoch 4/6 -- train_loss: 0.0057, val_loss: 0.0002, AP: 1.0\n",
      "TRANS Epoch 5/6 -- train_loss: 0.0037, val_loss: 0.0062, AP: 1.0\n",
      "TRANS Epoch 6/6 -- train_loss: 0.0134, val_loss: 0.0051, AP: 0.9999934253492234\n",
      "Transformer eval:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       981\n",
      "           1       1.00      1.00      1.00       674\n",
      "\n",
      "    accuracy                           1.00      1655\n",
      "   macro avg       1.00      1.00      1.00      1655\n",
      "weighted avg       1.00      1.00      1.00      1655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train LSTM\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=1e-3)\n",
    "EPOCHS = 6\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss = train_epoch(lstm_model, train_loader, optimizer, criterion)\n",
    "    val_loss, ys, preds, probs, ap = evaluate(lstm_model, val_loader, criterion)\n",
    "    print(f'LSTM Epoch {epoch+1}/{EPOCHS} -- train_loss: {tr_loss:.4f}, val_loss: {val_loss:.4f}, AP: {ap}')\n",
    "\n",
    "print('LSTM eval:')\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "# Train Transformer\n",
    "optimizer = torch.optim.Adam(trans_model.parameters(), lr=5e-4)\n",
    "EPOCHS = 6\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss = train_epoch(trans_model, train_loader, optimizer, criterion)\n",
    "    val_loss, ys_t, preds_t, probs_t, ap_t = evaluate(trans_model, val_loader, criterion)\n",
    "    print(f'TRANS Epoch {epoch+1}/{EPOCHS} -- train_loss: {tr_loss:.4f}, val_loss: {val_loss:.4f}, AP: {ap_t}')\n",
    "\n",
    "print('Transformer eval:')\n",
    "print(classification_report(ys_t, preds_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8615a244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Throughput (sequences/sec): LSTM=1302.1, Transformer=1050.6\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def measure_throughput(model, sample_tensor, runs=200):\n",
    "    model.eval()\n",
    "    sample = sample_tensor.to(device)\n",
    "    # warmup\n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(sample)\n",
    "    # timed runs\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(runs):\n",
    "            _ = model(sample)\n",
    "    t1 = time.time()\n",
    "    total = (t1 - t0)\n",
    "    secs_per_run = total / runs\n",
    "    return 1.0 / secs_per_run\n",
    "\n",
    "\n",
    "# pick a random sample from validation\n",
    "if len(X_val) > 0:\n",
    "    sample = torch.tensor(X_val[0:1], dtype=torch.float32)\n",
    "    lstm_tp = measure_throughput(lstm_model, sample, runs=200)\n",
    "    trans_tp = measure_throughput(trans_model, sample, runs=200)\n",
    "    print('Throughput (sequences/sec): LSTM=%.1f, Transformer=%.1f' % (lstm_tp, trans_tp))\n",
    "else:\n",
    "    print('No validation sequences to measure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "744bb041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript model: lstm_seq_model.pt\n"
     ]
    }
   ],
   "source": [
    "export_model = lstm_model.to('cpu')\n",
    "export_model.eval()\n",
    "example_input = torch.randn(1, WINDOW_SIZE, EMBED_DIM)\n",
    "traced = torch.jit.trace(export_model, example_input)\n",
    "traced.save('lstm_seq_model.pt')\n",
    "print('Saved TorchScript model: lstm_seq_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30b635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
